# On a Quest to the Cloud

Building any cloud service from scratch can be overwhelming for even the most experienced engineer. Even moreso when
the service just happens to be for a company obsessed with performance. Just look at some of our blog post titles:
[Importing 300k rows/sec with io_uring](https://questdb.io/blog/2022/09/12/importing-300k-rows-with-io-uring/),
[4Bn rows/sec query benchmark](https://questdb.io/blog/2022/05/26/query-benchmark-questdb-versus-clickhouse-timescale/),
or [Aggregating billions of rows per second with SIMD](https://questdb.io/blog/2020/04/02/using-simd-to-aggregate-billions-of-rows-per-second/).
We even rewrote much of the Java standard library to reduce memory usage and squeak as much performance out of it as possible.

So when Nic and Vlad came to the team and asked if we could build a QuestDB cloud service that lives up to all of the performance promises
we make, while also providing a straightforward and enjoyable user experience, needless to say, we were a little nervous.
But what engineer doesn't love building something new? You get to try out all of the cool stuff you read about on Hacker News,
you don't have to deal with legacy code, and you can even set many of your own requirements.

However, with this freedom comes a problem that is especially difficult in today's environment; choice. Which language should I use?
Which framework? Should I use a framework at all? What does the architecture look like? ow will we manage the infrastructure? Which
cloud provider should we use? Build vs buy? The questions are endless, and there is a real danger of paralysis-by-analysis.

It doesn't help that there are several completely reasonble answers to each question. Just look at the
[CNCF Landscape](https://landscape.cncf.io/) chart. There are over 1,175 different cloud native offerings,
and that just covers the infrastructure side. Each cloud provider has hundreds of services to choose from. For
every piece of infrastructure that you can build, you can also buy something that does _almost_ the same thing. But
even that has challenges; trying to compare the feature matrices and pricing plans of multiple vendors can
be a nightmare. And this doesn't even take into account the programming language and library choices that you need to make!

Despite these challenges, our team rose to the occasion. We made the required technology choices, built out what we thought were
necessary features, iterated on early customer feedback, built more features, hardended the infrastructure, and are now on the brink
of officially launching our QuestDB cloud service!

It was quite a journey to get here, and this is just the beginning of our journey. We'd like to take a moment to reflect
on what we've done so far, and hope that you can learn something based on the choices that we made (or at least give
you an opportunity to discuss in the comments section of wherever this is posted).

Let's start with the UI...

## UI

All good projects start with a well-prepared plan. Before writing any code, we sat down to make some forward-looking decisions.

### Initial Considerations
From the very beginning, one of our goals for QuestDB Cloud has been ease of use:
simply let the user select a preset, spin up a QuestDB database, and start working with it as quickly as possible.

We also wanted to provide a coherent, unified feel across our products: [QuestDB Web Console](https://demo.questdb.io/),
[documentation](https://questdb.io/docs/), and of course, the Cloud. A key component of our user experience is our data explorer
(QuestDB Web Console) that is the frontend for our open source database. It is already a slick and
battle-tested UI, and we knew that we would want to integrate it into the Cloud at some point.

Thus, we decided that the new Cloud project must leverage a similar stack and UI to minimize the amount of refactoring and redesign needed
to incorporate the existing web console. This would also make it easier to ensure that the Cloud UI has a consistent branding experience and color palette across
our entire web presence.

Furthermore, we did not want to build the Cloud on top of a fully-fledged and heavy UI framework. With quite a bit of
experience bootstrapping SaaS clients like Ant Design and Material UI, we were well
aware of how, as a project matures and complexity increases, it inevitably progresses towards phasing out larger frameworks in
favor of custom solutions.

We decided to opt for a headless and pluggable set of UI primitives - [Radix UI](https://www.radix-ui.com/). This, in
combination with natively supported [Styled Components](https://styled-components.com/), allows us to create a lightweight
component library quickly and extend it as needed, without carrying over an entire boilerplate, build config, or styling.

### The Tech Stack
Gone are the days of LAMPs or MEANs. For Cloud UI, we decided to use NextJS as our main framework. Even though we
have an amazing backend team to provide us with solid and well-thought APIs, leveraging some
key NextJS features helps us to quickly build new features.

For instance:

- It's trivial to prefetch data using [React Query](https://react-query-v3.tanstack.com/) within
[getServerSideProps](https://nextjs.org/docs/basic-features/data-fetching/get-server-side-props). This
 offloads major portions of page rendering to the server side, leveraging SSR and vastly improving initial load performance.
- Server-side API routes allow us to use third-party APIs for some features. We can easily integrate with products like
 Airtable, ProductBoard, or Slack while keeping both performance and security intact.
- With the support of [catch-all routes via spread operator](https://nextjs.org/docs/routing/dynamic-routes#catch-all-routes),
 we are able to create API middlewares that can read the HTTP request, ensure security and/or augment the payload or headers
 (authorization being one example). We can even go a step further by routing the request to the correct destination
 (like Python API on the backend) or even aggregate data from multiple sources.

### API Middlewares

We are often presented with a scenario where some backend API route is either a work in progress or doesn't exist. There
might be a proposed schema, but nothing is set in stone, or there is simply no stone at all.

But this shouldn't stop us from iterating on features! By writing an API middleware, we ensure that all
requests from the browser target the server side of NextJS, specifically a request handler at `pages/api/[…backend].ts`.

At first sight, this might seem just like an additional hurdle for us to jump in order to process a request; now the request
needs to go through the NodeJS server on its way to the main destination. However, this extra jump is tremendously worth its
performance cost cost by unlocking the following benefits:

- Single location to handle authorization headers
- Trivial mocking for non-existent or incomplete backend API routes
- Ability to integrate with other backend resources while keeping them all transparent to the user

This decision allows us to build [React Query](https://react-query-v3.tanstack.com/) abstractions (hooks, prefetch,
and all the associated toolkits) before the actual backend API is ready. For example, the frontend team can start
with mocked requests in, say, `pages/api/new-feature/endpoint.ts`. This file would take precedence over the
`pages/api/[…backend].ts` middleware and the developer is trivially able to provide any kind of request handler once
backend development is further along.

In addition, a catch-all API middleware let us hide implementation details from the client side. For example,
in Cloud UI we have a "Feedback" button. Clicking it shows a popup with a simple text form to collect user feedback.
Once the user clicks submit, the browser sends the request using the same API domain as it does for all other requests
(and not some `3rd-party-feedback-collector.com`).

Internally, within the NextJS API handler, we forward the request to… you guessed it, Slack! Yep, your feedback goes
straight to a dedicated #cloud-user-feedback channel where we can follow on any suggestions. We do actually read it all!

[TODO: Diagram image of the proxy here]

### How we stay lightweight
In a startup environment, when building an MVP (minimum viable product), there is an irresistible urge to snap on a library or a
plugin on everything without having to deal with implementation details. Just run `npm install` and move on, right?

On the surface, this shaves off days from the initial development hours, but this approach adds dependencies that inevitably
require more attention in the long run. For example, many popular libraries internally add even more more dependencies, and we
are unable to control this (`left-pad` anyone?).

Picking dependencies blindly can also explode the cost of maintenance over time. A week or more spent swapping out a dependency
in six months has a much greater cost than a few additional hours spent researching at the initial stage.

Consider our monitoring charts, which involve rendering graphs of customer database metrics. Because we use
[Apache ECharts](https://echarts.apache.org/) to render charts in the open source QuestDB Web Console, we
already have experience with a package that supports drawing any kind of plot type you can imagine. This, however,
even when shaving off as much size as possible with the help of named exports, gained us more
than 900 KB of weight that we would need to transmit across the wire.

Keeping in mind that line plots are only what we really need, along the team's familiarity with Grafana, we did some
research and discovered [uPlot](https://github.com/leeoniya/uPlot), which is a fantastic and extremely lightweight
(around 40KB) plotting library that powers the aforementioned observability powerhouse. Indeed, we struck gold with
Leon Sorokin's creation: not only it is minuscule, but the ability to render the time axis within a set range and given
incomplete data points is also mind-boggling. It also looks and feels familiar, which is an added bonus.

## Infrastructure

Ask 10 different SaaS, PaaS, or IaaS companies how they run their infrastructure, and you will almost certainly receive 10 different answers.
The infrastructure world is full of recent innovations, from managed cloud services to container orchestration platforms, IaaC solutions to provisioners,
and everything in between.

When designing a hosted service from scratch, it's important to choose the main characteristics that you want to optimize for. In our
case, we wanted to build a fully-featured, reliable, and automated service with a very small team size of just a few individuals. This
led us to some admittedly industry-standard choices in our technology decisions.

### Architecture

We decided to initially build our service on AWS for a simple reason; most of our prospective clients were also running there! Since
we pride ourselves on ingestion and query speed, we didn't want to introduce additional uncontrollable variables like network
latency that would not give customers the performance that they came to us for in the first place.

This led us to design a multi-region framework, allowing customers to deploy their own databases physically close to their infrastructure.
In order to do this effectively, we knew that we would need to employ IaC tools like Terraform to provision infrastructure
across regions (and in the future, across clouds!).

We also determined fairly early on that our initial Cloud offering would be single-tenant, mostly to make our lives easier.
As a single-tenant service, we wouldn't have to worry about the noisy-neighbor problem of multiple tenants competing for the same set
of node resources, We could also provision infrastructure to match our customers' demand on a 1-to-1 basis, keeping our costs down
by limiting the amount of infrastructure overprovisioning we would need.

Now that you have an idea of what we were aiming to do, let's dive into a few of the details:

### Terraform

We use Terraform to manage our core infrastructure on AWS. This includes leveraging the broad open-source community around
Terraform modules to help us spin up and manage some of the more complex resources, like EKS clusters. Each of our tenant regions
consists of an EKS cluster (and its supporting resources), and is entirely contained in a single Terraform module. This
allows us to quickly add or remove available regions, reduces blast-radius in case of errors, and forces us into solid software
development practices so we can write our IaC in an extensible and reusable manner. We also have a separate "management" cluster
that is used to host the Cloud frontend, backend, provisioner, and centralized monitoring infrastructure.

For each production environment, we also have a development one. Each dev environment is isolated in its own cluster, region, and
AWS account to prevent accidental data leakage or errant `terraform apply`s.

The structure of our terraform code is fairly simple. We don't use tools like Terragrunt, and instead maintain a
directory-per-environment module structure. We have a separate directory for shared modules and files, the former of which are
referenced by relative path, and the latter are added to each directory using soft links. Now that our shared code is
mostly stabilized, we found that the practice of making everything a versioned Terraform module was not worth the management overhead.
We don't have to bump module versions across multiple environments for every single change, and in the case of a major change,
can swap the symlink for a newer version of the shared file one module at-a-time for successive rollouts. Each module has
its own `*.tfvars` file with environment-specific overrides and settings.

If we want to add a new region, the Terraform work is mostly a copy-paste job. Most of the work is filling in a small number
of variables that are specific to the new region. All of this code goes into source control and follows code review best-practices
before it is applied. While we haven't yet reached the ability to automatically spin-up-and-down regions, it takes less than
one engineer-day's work to spin up a new region from scratch, including all of the AWS and Kubernetes infrastructure. This has
been sufficient for our current needs, since spinning up a new region shouldn't be something that happens regularly.

### Kubernetes

Over the past few years, Kubernetes (K8s) has become the go-to tool for hosting cloud-native applications. Not using it (or
a similar container orchestration tool) would require us to hand-roll a number of features including scheduling, security,
reliability, networking, monitoring, control planes, and more. Especially since we are a small team, we felt that it
was more important to quickly deliver value to customers in the form of a reliable database service, instead of spending our time
building a custom container orchestration platform and adding months to our delivery estimates (at best). But what kind of
performance implications would K8s have on our service?

To investigate this, we spent a lot of time benchmarking K8s to ensure that it wouldn't significantly impact QuestDB
performance. We carefully tuned our resource requirements to ensure that services like Kubelet wouldn't compete with user
database resources, and monitored QuestDB ingestion and query performance while running on K8s to measure its performance overhead.

After our benchmarks were completed, we were satisfied that QuestDB could still maintain its industry-leading performance while running
on a Kubernetes node loaded with the typical daemons and services such as Kubelet, promtail, calico, and node-exporter. Since QuestDB
is primarily I/O bound, we just need to ensure that we reserve some memory for these services to prevent OOMing the node.

### Metrics and Logs

We wanted users to be able to diagnose issues with their databases on their own; so they would need to see up-to-date instance
metrics and logs in our frontend. Luckily, working for a time-series database company has its advantanges! We were able to dogfood
our own QuestDB to store and serve instance metrics to our users. As detailed in [a blog post from last month](https://questdb.io/blog/questdb-cloud-metrics-kubernetes/),
we set up Prometheus remote writes to telegraf, which sends data to our metrics QuestDB server over ILP. This is automatically
set up in every new region that we spin up.

The application then queries QuestDB for metrics over the HTTP REST API. We chose this method because we do not need to manage
a separate database connection pool, like if we were connecting over pgwire. Instead, the application simply makes stateless HTTP calls
to the QuestDB API to query for instance metrics, making retries and timeouts trivial to implement.  In this sense, QuestDB is
acting like a common HTTP-based microservice.

As for logs, we used a Loki instance configured in "simple scalable deployment mode". This mode uses multiples of dedicated read
and write instances that communicate with a central gateway. This allows us to distribute reads and writes across our entire management
cluster, keeping the service tolerant against one or more node failures. This method requires the use of a blob store, so
naturally we chose AWS S3. We use Loki's built-in multi-tenant mode to isolate customer logs, so each customer gets
their own dedicated storage space that is guaranteed to only contain their instance logs.

To query for instance logs, the application makes an HTTP request to the Loki gateway over its REST API.  A reader node will
pick up the request, process the data, and return the results through the gateway.
